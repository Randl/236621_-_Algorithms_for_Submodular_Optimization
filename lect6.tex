\paragraph{Main idea}
For point $x\in [0,1]^N$ define distribution on subsets of $N$, $D_x$ such that for $R\sim D_x$:
\begin{align}
	P(i \in R) = x_i
\end{align}
Then we define 
\begin{align}
	F(x) = \mathbb{E}_{R\sim D_x} [f(R)]
\end{align}

\paragraph{Example}
For all $x$ choose $D_x$ such that $F(x)$ is maximized:
\begin{align}
f^+(x)  = \max\limits_{D_x}  \mathbb{E}_{R\sim D_x} [f(R)]
\end{align}
Similarly, we can choose $D_x$ such that $F(x)$ is minimized:
\begin{align}
f^-(x)  = \min\limits_{D_x}  \mathbb{E}_{R\sim D_x} [f(R)]
\end{align}

\begin{prop}
	$f^+$ is concave and $f^-$ is convex.
	\begin{proof}
		Let $x,y\in [0,1]^N$ lets show that for
		\begin{align}
			z = \lambda x + (1-\lambda)y
		\end{align}
		concave property is fulfilled:
		\begin{align}
		f^=(z) \geq \lambda f^+(x) +  (1-\lambda)f^+(y) 
		\end{align}
		Let $\qty{\alpha_S}_{S\subseteq N}$ be a distribution which defined $f(x)$: $P(R = S) = \alpha_S$, which fulfills:
		\begin{align}
		f^+(x) &= \mathbb{E}_{R\sim \alpha_S} [f(R)] \\
		\sum_{S: i\in S} \alpha_S &= x_i
		\end{align}
		Similarly, let $\qty{\beta_S}_{S\subseteq N}$ be a distribution defining $f(y)$.
		
		Now, take a look at linear combination of $\alpha_S$ and $\beta_S$:
		\begin{align}
		P(S) = \lambda\alpha_S + (1-\lambda)\beta_S
		\end{align}
		Note that this distribution conserves marginal values of $z$, since:
		\begin{align}
		\sum_{S: i\in S} \lambda \alpha_S + (1-\lambda) \beta_S = \lambda \sum_{S: i\in S} \alpha_S + (1-\lambda) \sum_{S: i\in S}\beta_S = \lambda x_i + (1-\lambda) y_i = z_i
		\end{align} 
		By definition,
		\begin{align}
		f^+(z) &\geq  \mathbb{E}_{R\sim\lambda \alpha_S + (1-\lambda) \beta_S} [f(R)] = \sum_{S \subseteq N} P(R=S) f(S) =\\&= \sum_{S \subseteq N} \qty[\lambda \alpha_S + (1-\lambda) \beta_S]f(S) = \lambda f^+(x) + (1-\lambda) f^+(y)
		\end{align}
	\end{proof}
\end{prop}

\begin{prop}
	Evaluating concave extensions of submodular function in some point is NP-hard.
\end{prop}

\begin{definition}[Lovasz extension]
	\begin{align}
	f_L(x) = \mathbb{E}_{\theta \sim [0,1]} [f\qty\big(\qty{i: x_i \geq \theta})]
	\end{align}
\end{definition}

\begin{theorem}[Lovasz]
	$f_L(x) = f^-(x)$ iff $f$ is submodular.
	\begin{proof}
		$\Leftarrow$:
		Denote $\qty{ \alpha_S}_{S\subseteq N}$ a distribution defining $f^-(x)$, and out of those the one that maximizes $\sum_{S \subseteq N} \alpha_S \abs{S}^2$.
		
		We'll show that for such $\alpha$, the sets for which $\alpha_S >0$ are chain (i.e., a set of sets such that for $A$, $B$ in the set either $A\subseteq B$ or $B\subseteq A$).
		
		Note that there is unique distribution that conserves marginal values and its support is chain: the Lovasz distribution. 
		
		Lets show how we can ''fix`` the distribution $\alpha_S$ which support is not a chain (uncrossing). Suppose there are $A,B$ such that $\alpha_A\geq \alpha_B >0$ and $A\not\subseteq B$ and  $B\not\subseteq A$.
		For that, lets reduce the probability of $A$ and $B$ by $\alpha_B$, and increase probability of $A\cap B$ and $A\cup B$ by $\alpha_B$.
		
		Does the new distribution conserve marginal values? For all of cases $x\in A\cap B$, $x\in A\setminus B$ and $x\in B\setminus A$, the probability did not change.
		
		What happened to $\mathbb{E} [f(R)]$? From submodularity,
		\begin{align}
		f(A) + f(B) \geq f(A\cap B) + f(A\cup B)
		\end{align}
		and since we removed LHS and added RHS multiplied same constant, the expectation can not grow.
		
		What happens to $\sum_{S \subseteq N} \alpha_S \abs{S}^2$?
		\begin{align}
		\abs{A\cup B}^2 + \abs{A\cap B}^2 &= \qty(\abs{A} + \abs{B\setminus A})^2 + \qty(\abs{B} - \abs{B\setminus A})^2 =\\&= \abs{A}^2+\abs{B}^2 + 2\abs{B\setminus A} \cdot \qty\big(\abs{A} - \abs{B} + \abs{B\setminus A}) =\\&= \abs{A}^2+\abs{B}^2 + 2\abs{B\setminus A}\underbrace{ \qty(\abs{A\cup B} - \abs{B})}_{>0} >  \abs{A}^2+\abs{B}^2
		\end{align}
		
		Thus, if we choose the set which maximizes $\sum_{S \subseteq N} \alpha_S \abs{S}^2$, there are no two sets $A,B$ such that $A\not\subseteq B$ and $B \not\subseteq A$, i.e., support is the chain.
		
		
		
		$\Rightarrow$:
	\end{proof}
\end{theorem}


\begin{definition}[Multilinear extension]
	\begin{align}
	F(x) = \sum_{S \subseteq N} f(S) \prod_{i\in S} x_i \prod_{i \notin S} (1-x_i)
	\end{align}
	i.e., each element is chosen independently.
\end{definition}
